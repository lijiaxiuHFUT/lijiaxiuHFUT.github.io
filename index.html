<!-- <!DOCTYPE html>
<html>
<body>
<h1>Hello World</h1>
<p>I'm hosted with GitHub Pages.</p>
</body>
</html>
 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Jiaxiu Li</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Jiaxiu Li</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://lijiaxiuHFUT.github.io/"><img src="picture/shushu.jpg" alt="alt text" width="120px" /></a>&nbsp;</td>
<!-- <td align="left"><p>本科生,暂时还不是党员<br /> -->
<td align="left">计算机科学与技术, <a href="https://ci.hfut.edu.cn/">计算机学院</a>, <br />
翡翠湖校区, <br />
<a href="http://www.hfut.edu.cn/">合肥工业大学</a>, <br />
合肥, 安徽, 中国 <br />
手机: +86   <br /> 
邮箱: jiaxiuli@mail.hfut.edu.cn <br />

<!--  <br /> <a href="https://github.com/lijiaxiuHFUT">[GitHub]<a href="EnHome.html">[English Page]</a></p>
 -->
 <br /> <a href="https://github.com/lijiaxiuHFUT">[GitHub]<a href="EnHome.html">[English Page]</a></p>


  
 <!--  
<br />
<a href="pdf/Aikun_Xu_CV.pdf">[我的简历]</a> <a href="https://scholar.google.com/citations?user=-dqI968AAAAJ&hl=zh-CN">[Google Scholar]</a> 
  <a href="https://github.com/xuaikun">[GitHub]<a href="EnHome.html">[English Page]</a></p>
  -->
 
</td></tr></table>
<h2>关于我</h2>
<p>我现在是一名大学四年级的学生(将于2024年6月毕业), 就读于<a href="http://www.hfut.edu.cn/">合肥工业大学</a> <a href="https://ci.hfut.edu.cn/">计算机学院</a>。
我的专业为计算机科学与技术, 专业排名:(44/156)。</p>
<!-- <p>我的研究兴趣主要包括: 多模态学习，视频定位(Video Temporal Grounding)，视觉定位(Visual Grounding)。</p> -->
<p>在本科阶段的学习过程中，我以实习生的身份加入了<a href="https://vut-hfut.github.io/">媒体计算实验室</a>，在<a href=" http://faculty.hfut.edu.cn/gd/zh_CN/index.htm">郭丹教授</a>
的指导下对多模态学习、视频定位任务，
 进行了较为深入的科学研究与探索，并且发表了部分论文。除此之外， 我深入的学习了C++、python语言，熟悉了pytorch等其他神经网络工具。</p>
 <p>总的来说，我是一个乐观向上，自学能力强，有钻研精神，吃苦耐劳的人。我对待工作认真积极，愿意积极探索学习新事物，具有较强的抗压能力</p>

<h2>教育经历</h2>
 
<table class="imgtable"><tr><td>
<a href="https://www.hfut.edu.cn/"><img src="picture/hfut.jpg" alt="合肥工业大学" width="80px" /></a>&nbsp;</td>
<td align="left"> <a href="https://www.hfut.edu.cn/">合肥工业大学</a> (2020.9 ~ 2024.7)</h3>
<ul>
<li><p><b>院系专业</b>: 计算机与信息学院, 计算机科学与技术</p>
</li>
<li><p>GPA</b>: 3.52/4.3 <a href="picture/Academic_transcript.jpg">[成绩单]</a></p>
</li>
<li><p><b>奖学金</b>: 校三等奖学金(2021.10)、校三等奖学金(2022.9) <br /></p>
</li>
<li><p><b>英语成绩</b> CET-4: 572<a href="picture/cet4.jpg">[证书]</a> CET-6: 453<a href="picture/cet6.jpg">[证书]</a></p>
</li>
<!-- <li><p><b>荣誉称号</b>: <br /></p>
</li> -->
<li><p><b>比赛获奖</b>: 互联网+校赛三等奖、数学建模校赛三等奖</p>
</li>
</ul>
</td></tr></table>
 
<h2>学术论文</h2>

<ul>
<li><p><a href="https://arxiv.org/abs/2309.06176">Dual-Path Temporal Map Optimization for Make-up Temporal Video Grounding</a> <br />
<b>Jiaxiu Li</b>, Kun Li, Jia Li, Guoliang Chen, Dan Guo and Meng Wang <br />
<i>Multimedia Systems, 2024 [CCF C]</i> <br />
主要内容：本论文提出一种双路时序图优化网络，用于化妆视频定位任务。化妆视频相比于其他视频包含更加丰富的细粒度信息，对视频定位模型提出了较高的要求。该模型通过使用双路结构，同时对单模态特征与跨模态特征进行建模，并分别使用度量学习和IoU回归的方法计算损失。实验证明该模型在Youmakeup数据集上获得了较高的性能。

</p>
</li>
</ul> 

<ul>
<li><p><a href="https://doi.acm.org?doi=3587251">Transformer-based Visual Grounding with Cross-modality Interaction</a> <br />
Kun Li, <b>Jiaxiu Li</b>, Dan Guo, Xun Yang and Meng Wang <br />
<i>ACM Transactions on Multimedia Computing, Communications, and Applications <b>(TOMM)</b>, 2022. [CCF B]<a href="paper/TOMM_2022-0408_Final Version.pdf">[PDF]</a></i><br />
主要内容：<br />
 （1）构建模型网络：通过使用transformer架构完成协同注意力机制（co-attention）模块，增强模型对跨模态信息的学习能力 <br />
 （2）消融实验设计与实验可视化：分别构造单流模态交互和模态内建模网络架构对比跨模态交互网络效果，并使用matplotlib工具对不同模态的特征图进行可视化。
 （3）论文撰写：使用Latex工具对论文的图表与部分内容进行绘制与完成
</li>
</ul>
<ul>  
<li><p><a href="https://ceur-ws.org/Vol-3522/paper_4.pdf">Multi-modality Fusion for Emotion Recognition in Videos</a> <br />
Xinge Peng, Kun Li, <b>Jiaxiu Li</b>, Guoliang Chen and Dan Guo <br />
<i>International IJCAI Workshop on Micro-gesture Analysis for Hidden Emotion Understanding.[CCFA workshop] <a href="paper/workshop_VER_submit.pdf">[PDF]</a></i><br />
主要内容：（1）Linux平台上代码的训练测试（2）使用ppt等科研工具对论文主题模型图进行绘制
</li>
</ul>

<h2>其他项目</h2>
<ul>
<li><p> 基于视觉-语言交互理解的智能室内导航系统(S202210359075)<br />
<b>负责人</b>;  经费:8000元 <br />
大学生创新创业训练项目(<b>省级</b>) <br />
主要内容： 通过搭建Matterport3D Simulator平台与使用Docker工具，复现<a href="https://github.com/YicongHong/Recurrent-VLN-BERT">VLNBERT</a>模型，并在测试其在Room-to-room数据集上的性能。
</p>
</li>
</ul>
 
<div id="footer">
<div id="footer-text">
<br>Page generated 2023-03-08, by <a href="https://lijiaxiuHFUT.github.io/">Jiaxiu Li</a>.
</div>
</div>
</div>
</body>
</html>
